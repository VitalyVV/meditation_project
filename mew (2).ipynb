{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib as mlt\n",
    "import mne\n",
    "import statistics \n",
    "from pathlib import Path\n",
    "from mne.preprocessing import ICA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from mne.filter import filter_data \n",
    "%matplotlib inline\n",
    "mne.set_log_level('CRITICAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code snippet for file processing, example of using below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def microvolts_to_volts(value):\n",
    "    \"\"\"\n",
    "    Since openBCI writes data into micro volts and mne works with volts we\n",
    "    will need to convert the data later.\n",
    "    :param value: single micro volts value\n",
    "    :return: same value in volts\n",
    "    \"\"\"\n",
    "    return float(value) / 1000\n",
    "\n",
    "\n",
    "def load_openbci_file(filename, ch_names=None, skiprows=0, max_rows=0):\n",
    "    \"\"\"\n",
    "    Load data from OpenBCI file into mne RawArray for later use\n",
    "    :param filename: filename for reading in form of relative path from working directory\n",
    "    :param ch_names: dictionary having all or some channels like this:\n",
    "            {\"fp1\":1, \"fp2\":2, \"c3\":3, \"c4\":4, \"o1\":5, \"o2\":6, \"p3\":7, \"p4\":8}\n",
    "            Key specifies position on head using 10-20 standard and\n",
    "            Value referring to channel number on Cyton BCI board\n",
    "    :return: RawArray class of mne.io library\n",
    "    \"\"\"\n",
    "    if ch_names is None:\n",
    "        ch_names = {\"fp1\":1, \"fp2\":2, \"c3\":3, \"c4\":4, \"o1\":5, \"o2\":6, \"p3\":7, \"p4\":8}\n",
    "\n",
    "    # Converter of BCI file to valuable data\n",
    "    converter = {i: (microvolts_to_volts if i < 12 else lambda x: str(x).split(\".\")[1][:-1])\n",
    "                 for i in range(0, 13)}\n",
    "\n",
    "    info = mne.create_info(\n",
    "        ch_names=list(ch_names.keys()),\n",
    "        ch_types=['eeg' for i in range(0, len(ch_names))],\n",
    "        sfreq=250,\n",
    "        montage='standard_1020'\n",
    "    )\n",
    "    data = np.loadtxt(filename, comments=\"%\", delimiter=\",\",\n",
    "                      converters=converter, skiprows=skiprows, max_rows=max_rows).T\n",
    "    data = data[list(ch_names.values())]\n",
    "    data = filter_data(data, 250, l_freq=2, h_freq=50)\n",
    "#     print ('data type', type(data), '  shape  ' , data.shape)\n",
    "    return mne.io.RawArray(data, info)\n",
    "\n",
    "\n",
    "def create_epochs(raw_data, duration=1):\n",
    "    \"\"\"\n",
    "    Chops the RawArray onto Epochs given the time duration of every epoch\n",
    "    :param raw_data: mne.io.RawArray instance\n",
    "    :param duration: seconds for copping\n",
    "    :return: mne Epochs class\n",
    "    \"\"\"\n",
    "    events = mne.make_fixed_length_events(raw_data, duration=duration)\n",
    "    epochs = mne.Epochs(raw_data, events, preload=True)\n",
    "    return epochs\n",
    "\n",
    "def create_epochs_with_baseline(raw_data, baseline, duration=1):\n",
    "    \"\"\"\n",
    "    Chops the RawArray onto Epochs given the time duration of every epoch\n",
    "    :param raw_data: mne.io.RawArray instance\n",
    "    :param duration: seconds for copping\n",
    "    :return: mne Epochs class\n",
    "    \"\"\"\n",
    "    events = mne.make_fixed_length_events(raw_data, duration=duration)\n",
    "    epochs = mne.Epochs(raw_data, events, preload=True, baseline=baseline)\n",
    "    return epochs\n",
    "\n",
    "\n",
    "def get_files(dir='.', pattern='*.txt'):\n",
    "    \"\"\"\n",
    "    Loading files from given directory with specified pattern.\n",
    "    :param dir: Lookup directory\n",
    "    :param pattern: Pattern for files. Default *.txt for loading raw BCI files\n",
    "    :return: array of file paths\n",
    "    \"\"\"\n",
    "    # Specifying files directory, select all the files from there which is txt\n",
    "    datadir = Path(dir).glob(pattern)\n",
    "    # Transferring generator into array of file paths\n",
    "    return [x for x in datadir]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_data(path, regx, skiprow=10000, max_row=133000):\n",
    "    files = get_files(path, regx)\n",
    "    ch_names = {\"fp2\":1, \"fp1\":2, \"f4\":3, \"f3\":4, \"c4\":5, \"c3\":6, \"o2\":7, \"o1\":8}\n",
    "    raw_data = []\n",
    "    raw_baselines = []\n",
    "#     file = files[-1]\n",
    "#     print(file)\n",
    "#     raw_data.append(load_openbci_file(file, ch_names=ch_names, skiprows=skiprow, max_rows=max_row))\n",
    "    \n",
    "#     return create_epochs(raw_data[0])  \n",
    "    \n",
    "    for file in files:\n",
    "        raw_data.append(load_openbci_file(file, ch_names=ch_names, skiprows=skiprow, max_rows=max_row))\n",
    "        baseline_subj = str(file).split('_')[2]\n",
    "        baseline_sess = str(file).split('_')[3]\n",
    "        raw_baselines.append( '*' + baseline_subj + '*' + baseline_sess + '*Baseline*')\n",
    "        \n",
    "    real_data_series = [create_epochs(raw) for raw in raw_data]\n",
    "    return real_data_series, raw_baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Constants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " # TAKE ONE RANDOM RECORDING FOR PLOTTING\n",
    "n_channels = 8\n",
    "SAMPLE_FREQ = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next applying ICA and print the filters.\n",
    "\n",
    "Note: Filter ID may not be the same as channel ID.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_ICA(sample_data):\n",
    "    ica = ICA()\n",
    "    ica.fit(sample_data)\n",
    "    return ica.apply(sample_data) # Transform recording into ICA space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert data into vector\n",
    "Try different approaches. Next is an attempt to see overall recording waves.\n",
    "Free to change everything next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_epochs(data_epochs):\n",
    "    dat = data_epochs.get_data()\n",
    "    data = np.zeros( (dat.shape[0] * dat.shape[2], 8) )\n",
    "    n_epoch = len(dat)\n",
    "    n_in_epoch = dat.shape[2]\n",
    "    for i in range(n_epoch):\n",
    "        data[i*n_in_epoch:i*n_in_epoch + n_in_epoch] = dat[i].T\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_table(data):\n",
    "    # Get real amplitudes of FFT (only in postive frequencies)\n",
    "    fft_vals = np.absolute(np.fft.rfft(data))\n",
    "\n",
    "    # Get frequencies for amplitudes in Hz\n",
    "    fft_freq = np.fft.rfftfreq(len(data), 1.0/SAMPLE_FREQ)\n",
    "    # Define EEG bands\n",
    "    eeg_bands = {'Delta': (0, 4),\n",
    "                 'Theta': (4, 8),\n",
    "                 'Alpha': (8, 12),\n",
    "                 'Beta': (12, 30),\n",
    "                 'Gamma': (30, 45)}\n",
    "\n",
    "    # Take the mean of the fft amplitude for each EEG band\n",
    "    eeg_band_fft = dict()\n",
    "    for band in eeg_bands:  \n",
    "        freq_ix = np.where((fft_freq >= eeg_bands[band][0]) & \n",
    "                           (fft_freq <= eeg_bands[band][1]))[0]\n",
    "        eeg_band_fft[band] = np.mean(fft_vals[freq_ix])\n",
    "\n",
    "    # Plot the data (using pandas here cause it's easy)\n",
    "\n",
    "    df = pd.DataFrame(columns=['band', 'val'])\n",
    "    df['band'] = eeg_bands.keys()\n",
    "    df['val'] = [eeg_band_fft[band] for band in eeg_bands]\n",
    "    ax = df.plot.bar(x='band', y='val', legend=False)\n",
    "    ax.set_xlabel(\"EEG band\")\n",
    "    ax.set_ylabel(\"Mean band Amplitude\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table_of_coding.iloc[2, 1] / table_of_coding.iloc[4, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table_of_coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(sample_data, waves1='Alpha', waves2='Gamma'):\n",
    "    vector = []\n",
    "    # Define EEG bands\n",
    "    eeg_bands = {'Delta': (0, 4),\n",
    "                 'Theta': (4, 8),\n",
    "                 'Alpha': (8, 12),\n",
    "                 'Beta': (12, 30),\n",
    "                 'Gamma': (30, 45)}\n",
    "    \n",
    "    \n",
    "    ch_names = {\"fp2\":0, \"fp1\":1, \"f4\":2, \"f3\":3, \"c4\":4, \"c3\":5, \"o2\":6, \"o1\":7}\n",
    "    \n",
    "    \n",
    "    analysis_data = np.zeros( (sample_data.shape[0], sample_data.shape[1]//2, sample_data.shape[2]) )\n",
    "    i = 0\n",
    "    \n",
    "    # Calculate hemisphere difference ratio left / right\n",
    "    for sample_epoch in sample_data:\n",
    "        analysis_data[i][0] = (sample_epoch[1] - sample_epoch[0]) / (sample_epoch[1] + sample_epoch[0])\n",
    "        analysis_data[i][1] = (sample_epoch[3] - sample_epoch[2]) / (sample_epoch[3] + sample_epoch[2])\n",
    "        analysis_data[i][2] = (sample_epoch[5] - sample_epoch[4]) / (sample_epoch[5] + sample_epoch[4])\n",
    "        analysis_data[i][3] = (sample_epoch[7] - sample_epoch[6]) / (sample_epoch[7] + sample_epoch[6])\n",
    "        i+=1\n",
    "    \n",
    "#     vector = np.zeros((i,1))\n",
    "    for epoch in analysis_data:\n",
    "    \n",
    "     # Get real amplitudes of FFT (only in postive frequencies)\n",
    "        fft_vals = np.absolute(np.fft.rfft(epoch.T))\n",
    "\n",
    "        # Get frequencies for amplitudes in Hz\n",
    "        fft_freq = np.fft.rfftfreq(len(epoch.T), 1.0/SAMPLE_FREQ)\n",
    "        eeg_band_fft = dict()\n",
    "    \n",
    "        for band in eeg_bands:\n",
    "            freq_ix = np.where((fft_freq >= eeg_bands[band][0]) & \n",
    "                               (fft_freq <= eeg_bands[band][1]))[0]\n",
    "            eeg_band_fft[band] = np.mean(fft_vals[freq_ix])\n",
    "    \n",
    "        vector.append(eeg_band_fft[waves1] / eeg_band_fft[waves2])\n",
    "\n",
    "    return np.array(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_absolute_baseline(data, baseline):\n",
    "    baseline = vectorize(baseline)\n",
    "    baseline = mlt.repmat(baseline, 1, int(np.ceil(len(data)/len(baseline))))[0]\n",
    "    base = baseline[:len(data)]\n",
    "#     print('Base shape', base.shape)\n",
    "#     print('Data shape', data.shape)\n",
    "    data = data.reshape(9, int(np.ceil(len(data)/9)))\n",
    "    base = base.reshape(9, int(np.ceil(len(base)/9)))\n",
    "#     print('Base shape', base.shape)\n",
    "#     print('Data shape', data.shape)\n",
    "    data = np.mean(data.T, axis=1)\n",
    "    base = np.mean(base.T, axis=1)\n",
    "#     print('Base shape', base.shape)\n",
    "#     print('Data shape', data.shape)\n",
    "    \n",
    "    return data - base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_baseline(subj_data, subj_name):\n",
    "    base = get_files('Dataset/', subj_name)\n",
    "    print(base)\n",
    "    ch_names = {\"fp2\":1, \"fp1\":2, \"f4\":3, \"f3\":4, \"c4\":5, \"c3\":6, \"o2\":7, \"o1\":8}\n",
    "    base = load_openbci_file(base[0], ch_names=ch_names, skiprows=1000, max_rows=20000)\n",
    "    base = create_epochs(base).get_data()\n",
    "    \n",
    "    subj_data = vectorize(subj_data.get_data())\n",
    "    base = vectorize(base)\n",
    "    base = mlt.repmat(base, 1, int(np.ceil(len(subj_data)/len(base))))[0]\n",
    "    base = base[:len(subj_data)]\n",
    "    \n",
    "    return spatial.distance.euclidean(subj_data, base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_baseline(subj_data, subj_name):\n",
    "    base = get_files('Dataset/', subj_name)\n",
    "    ch_names = {\"fp2\":1, \"fp1\":2, \"f4\":3, \"f3\":4, \"c4\":5, \"c3\":6, \"o2\":7, \"o1\":8}\n",
    "    base = load_openbci_file(base[0], ch_names=ch_names, skiprows=1000, max_rows=20000)\n",
    "    base = create_epochs(base).get_data()\n",
    "    \n",
    "    subj_data = vectorize(subj_data.get_data())\n",
    "    \n",
    "#     print(base.shape)\n",
    "#     print(subj7_data.shape)\n",
    "\n",
    "    return apply_absolute_baseline(subj_data, base)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from scipy import spatial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_codings, baselines = get_sample_data('Dataset/', '*Session1*Coding.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WindowsPath('Dataset/OpenBCI-RAW-2019-06-14_13-06-50_Subject9_Session1_Baseline.txt')]\n",
      "[WindowsPath('Dataset/OpenBCI-RAW-2019-06-26_10-13-58_Subject17_Session1_Baseline.txt')]\n",
      "[WindowsPath('Dataset/OpenBCI-RAW-2019-06-26_20-37-49_Subject7_Session1_Baseline.txt')]\n",
      "248.8195412611641\n"
     ]
    }
   ],
   "source": [
    "mean = 0\n",
    "means = []\n",
    "del raw_codings[1]\n",
    "del raw_codings[1]\n",
    "del raw_codings[1]\n",
    "\n",
    "del baselines[1]\n",
    "del baselines[1]\n",
    "del baselines[1]\n",
    "\n",
    "for datas in zip(raw_codings, baselines):\n",
    "    data = transform_ICA(datas[0])\n",
    "    compared = compare_baseline(data, datas[1])\n",
    "    means.append(compared)\n",
    "    mean += compared\n",
    "    \n",
    "print(mean / len(raw_codings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_codingmeds, baselines = get_sample_data('Dataset/', '*Session2*Codingmed*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WindowsPath('Dataset/OpenBCI-RAW-2019-06-17_19-03-41_Subject11_Session2_Baseline.txt')]\n",
      "190.3834848516326\n"
     ]
    }
   ],
   "source": [
    "mean_codemed = 0\n",
    "meanscm = []\n",
    "for datas in zip(raw_codingmeds, baselines):\n",
    "    data = transform_ICA(datas[0])\n",
    "    compared = compare_baseline(data, datas[1])\n",
    "    meanscm.append(compared)\n",
    "    mean_codemed += compared\n",
    "\n",
    "print(mean_codemed / len(raw_codingmeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_codings2, baselines = get_sample_data('Dataset/', '*Session2*Coding.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WindowsPath('Dataset/OpenBCI-RAW-2019-06-06_21-33-31_Subject7_Session2_Baseline.txt')]\n",
      "[WindowsPath('Dataset/OpenBCI-RAW-2019-06-08_19-13-48_Subject8_Session2_Baseline.txt')]\n",
      "[WindowsPath('Dataset/OpenBCI-RAW-2019-06-15_14-14-29_Subject9_Session2_Baseline.txt')]\n",
      "312.1653154998669\n"
     ]
    }
   ],
   "source": [
    "mean_codeses2 = 0\n",
    "means2 = []\n",
    "for datas in zip(raw_codings2, baselines):\n",
    "    data = transform_ICA(datas[0])\n",
    "    compared = compare_baseline(data, datas[1])\n",
    "    means2.append(compared)\n",
    "    mean_codeses2 += compared\n",
    "    \n",
    "print(mean_codeses2 / len(raw_codings2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_meds, baselines = get_sample_data('Dataset/', '*Session2*Meditation*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WindowsPath('Dataset/OpenBCI-RAW-2019-06-17_19-03-41_Subject11_Session2_Baseline.txt')]\n",
      "241.2497604007325\n"
     ]
    }
   ],
   "source": [
    "mean_medit = 0\n",
    "medmeans = []\n",
    "for datas in zip(raw_meds, baselines):\n",
    "    data = transform_ICA(datas[0])\n",
    "    compared = compare_baseline(data, datas[1])\n",
    "    medmeans.append(compared)\n",
    "    mean_medit += compared\n",
    "    \n",
    "print(mean_medit / len(raw_meds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[515.5456330112872, 187.00209281312814, 43.91089795907696]\n",
      "[190.3834848516326]\n",
      "[258.5692619520419, 269.2432399574976, 408.6834445900611]\n",
      "[241.2497604007325]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "print(means)\n",
    "print(meanscm)\n",
    "print(means2)\n",
    "print(medmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`bins` must increase monotonically, when an array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-7cb149bb7819>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mxaxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcoding1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoding2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcodingmed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\datamining\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mhist\u001b[1;34m(x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, normed, data, **kwargs)\u001b[0m\n\u001b[0;32m   2659\u001b[0m         \u001b[0malign\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malign\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m         \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacked\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnormed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2661\u001b[1;33m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2662\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2663\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\datamining\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1808\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1810\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\datamining\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mhist\u001b[1;34m(self, x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, normed, **kwargs)\u001b[0m\n\u001b[0;32m   6589\u001b[0m             \u001b[1;31m# this will automatically overwrite bins,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6590\u001b[0m             \u001b[1;31m# so that each histogram uses the same bins\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6591\u001b[1;33m             \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhist_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6592\u001b[0m             \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# causes problems later if it's an int\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6593\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmlast\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\datamining\\lib\\site-packages\\numpy\\lib\\histograms.py\u001b[0m in \u001b[0;36mhistogram\u001b[1;34m(a, bins, range, normed, weights, density)\u001b[0m\n\u001b[0;32m    778\u001b[0m     \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ravel_and_check_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m     \u001b[0mbin_edges\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniform_bins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_bin_edges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m     \u001b[1;31m# Histogram is an integer or a float array depending on the weights.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\datamining\\lib\\site-packages\\numpy\\lib\\histograms.py\u001b[0m in \u001b[0;36m_get_bin_edges\u001b[1;34m(a, bins, range, weights)\u001b[0m\n\u001b[0;32m    421\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbin_edges\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbin_edges\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m             raise ValueError(\n\u001b[1;32m--> 423\u001b[1;33m                 '`bins` must increase monotonically, when an array')\n\u001b[0m\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: `bins` must increase monotonically, when an array"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "coding1 = 248.8195412611641\n",
    "codingmed = 190.3834848516326\n",
    "coding2 = 312.1653154998669\n",
    "\n",
    "legend = ['Coding 1', 'Coding 2', 'Meditation + Coding']\n",
    "xaxs = np.linspace(0, 100, 3)\n",
    "\n",
    "plt.hist([coding1, coding2, codingmed])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
