{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2></h2>\n",
    "<p></p>\n",
    "<h1>Analysing BCI data</h1>\n",
    "<p>\n",
    "This tutorial will give some explanations of BCI data analysis. We will do it with using python mne library, but in other languages and libraries should me analogs. Some actual code you can find <a href=\"https://github.com/VitalyVV/meditation_project/blob/master/Untitled.ipynb\">here</a>.\n",
    "</p>\n",
    "<h2>Why we need to analyse BCI data?</h2>\n",
    "<p>The success of the experiment lies not only in the correct formulation of the experiment itself, but also in the correct analysis of the data received from BCI, so we should make proper analysis of it..</p>\n",
    "<h2>Steps of analysis:</h2>\n",
    "<ol>\n",
    "    <li>\n",
    "        <p>First of all, we should collect and load our data. If the experiment was carried out correctly and we have proper data obtained from the BCi, we need to bring data to a certain format (if this was not done automatically or if the data was taken from several sources). After that we have to upload them for further processing.\n",
    "        </p>\n",
    "    </li>\n",
    "    <li>\n",
    "        <p>After loading data we need to make preprocessing: cut unneeded parts and filter data. | Some information obtained from the BCI is often redundant, that is, they have extra parts (for example, sample indexes, accel data, time stamps or aux data). If this information is not needed for analysis, it is worth cutting it out, because extra data for analysis entail additional error and resource costs. | Also, when working with the BCI, it is necessary to take into account data contamination: it may be external stimuli such as the electrical network or information that interferes with research such as some body movements. This data must be filtered, because otherwise the data will carry a lot of interference and the error will be high.\n",
    "        </p>\n",
    "    </li>\n",
    "    <li>\n",
    "        <p>After preprocessing we should format our data in correspondence with functions, that we will use. | When working with functions and libraries, you should pay attention to the format of input and output data, because for most of the functions data should be strictly formatted.\n",
    "        </p>\n",
    "    </li>\n",
    "    <li>\n",
    "        <p>Then we preprocessed and formatted our data, we should develop some interpretation of this data. | The data received from BCI itself does not carry the meaning, if not interpreted. You need to come up with ideas on how to get something worthwhile from the data. The conclusion of the study is built on the basis of interpretation. This step should be treated very carefully.\n",
    "        </p>\n",
    "    </li>\n",
    "    <li>\n",
    "        <p>We also can make some visualisations. | Some information is easier to perceive and analyze visually. So you can see what to look for during data interpretation. This step can be carried out both before and after the interpretation of the data.\n",
    "        </p>\n",
    "    </li>\n",
    "\n",
    "</ol>\n",
    "<h2>Why it is enough?</h2>\n",
    "<p>Performing the above steps is sufficient for data analysis. We got rid of the artifacts in the record obtained from the interface and filtered the data in a certain range, thereby obtaining pure processed data suitable for analysis. Therefore, the interpretation and visualization, if they are designed correctly, will give us with high probability useful data with which you can work in the study.</p>\n",
    "<h2>More details with examples</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we need to import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "from pathlib import Path\n",
    "from mne.preprocessing import ICA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from mne.filter import filter_data \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Collecting and Loading</h3>\n",
    "<p>If you have prepaired formatted data, you can skip step of preformatting.</p>\n",
    "<p>It is often better to have data in one format, so working with it will be much easier. In our study file format is following:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%OpenBCI Raw EEG Data\n",
      "%Number of channels = 8\n",
      "%Sample Rate = 250.0 Hz\n",
      "%First Column = SampleIndex\n",
      "%Last Column = Timestamp \n",
      "%Other Columns = EEG data in microvolts followed by Accel Data (in G) interleaved with Aux Data\n",
      "0, 0.00, -476.03, -1125.54, -1217.12, -1151.03, -1294.34, -1167.79, -994.50, -0.006, -0.176, 1.014, 13:15:54.702, 1553940954702\n",
      "1, 0.00, -473.97, -1126.24, -1213.34, -1150.35, -1291.35, -1165.33, -991.43, 0.000, 0.000, 0.000, 13:15:54.762, 1553940954762\n",
      "2, 0.00, -481.61, -1134.95, -1223.96, -1158.65, -1301.18, -1171.97, -1001.65, 0.000, 0.000, 0.000, 13:15:54.762, 1553940954762\n",
      "3, 0.00, -489.50, -1140.30, -1235.65, -1163.79, -1312.16, -1180.82, -1012.47, 0.000, 0.000, 0.000, 13:15:54.762, 1553940954762\n"
     ]
    }
   ],
   "source": [
    "filename=\"example_data.txt\"\n",
    "file = open(filename, \"r\").readlines()\n",
    "for line in file:\n",
    "    print(line[:-1])\n",
    "    if line[0]=='3':\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Here strokes starting from \"%\" are comments which describe strokes of data. After comments are placed all data received from BCI in format specified in comments.\n",
    "</p>\n",
    "<p>In our study we have some problem with EEG data, because it is given to us in microvolts, but mne library works only with volts. That's why we need to convert units:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def microvolts_to_volts(value):\n",
    "    \"\"\"\n",
    "    Since openBCI writes data into micro volts and mne works with volts we\n",
    "    will need to convert the data later.\n",
    "    :param value: single micro volts value\n",
    "    :return: same value in volts\n",
    "    \"\"\"\n",
    "    return float(value) / 1000\n",
    "\n",
    "# Converter of BCI file to valuable data\n",
    "converter = {i: (microvolts_to_volts if i < 12 else lambda x: str(x).split(\".\")[1][:-1])\n",
    "    for i in range(0, 13)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>After formatting all data we can load data and specify all parameters. In our study we work with <a href=\"https://martinos.org/mne/dev/generated/mne.io.RawArray.html\">mne library RawArray</a>. To build correct and readable data with it we should specify channel's names, channel's types, sample frequency and montage standart.</p>\n",
    "<p>In our study we have 8 EEG channels in standart 10-20: fp2, fp1, f4, f3, c4, c3, o2, o1. And our sample rate is 250 Hz. We create instance of info (from mne library) and give all this data into it. Note that order of channels is referring to channel number on Cyton BCI board.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_names = {\"fp2\":1, \"fp1\":2, \"f4\":3, \"f3\":4, \"c4\":5, \"c3\":6, \"o2\":7, \"o1\":8}\n",
    "\n",
    "info = mne.create_info(\n",
    "        ch_names=list(ch_names.keys()),\n",
    "        ch_types=['eeg' for i in range(0, len(ch_names))],\n",
    "        sfreq=250,\n",
    "        montage='standard_1020'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now we should actually load our data. Often loading functions also have some loading options, like specifying format of data, comments and etc. In our study we skip first and last 10000 rows (40 seconds) of data, because these parts are testing data, which has no meaning. In our format comments start from \"%\" and all data is separated by \",\". So we wrote this in function attributes. Was used <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.loadtxt.html\">numpy function loadtxt.</a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "skiprows = 10000\n",
    "max_rows = 50000\n",
    "raw_data = np.loadtxt(filename, comments=\"%\", delimiter=\",\", converters=converter, skiprows=skiprows, max_rows=max_rows).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading raw data looks like N-dimensional array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 50000)\n"
     ]
    }
   ],
   "source": [
    "print(raw_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 14 columns of data and many rows. We had the same picture in example_data.txt file, so we assume, that loading was completed correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Preprocessing</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In preprocessing step we should make filtering of our data and cut everything unneeded. At first it is better to cut data, because filtering is resource-consuming process and we should cut data beforehand. In our study we need only data from our channels, so we don't need order numbers, accel and aux data:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_data = raw_data[list(ch_names.values())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cutting sizes of our array should lessen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 50000)\n"
     ]
    }
   ],
   "source": [
    "print(cut_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now we have only 8 needed channels, so cutting was done correctly.</p>\n",
    "<p>After that we can filter data. We may have to complete complicated filtering, like cutting off artifacts. It can be done via fourier (or wavelet) transform. But in our study we decided to only cut frequencies in range [2:50] Hz, because too high and low frequencies are not related to our study. We made it through mne library, using <a href=\"https://martinos.org/mne/dev/generated/mne.filter.filter_data.html\">filter_data function</a>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up band-pass filter from 2 - 50 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 2.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 1.00 Hz)\n",
      "- Upper passband edge: 50.00 Hz\n",
      "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
      "- Filter length: 413 samples (1.652 sec)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_data = filter_data(cut_data, 250, l_freq=2, h_freq=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After filtering sizes of our array should remain the same, but data inside of array cells should differ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 50000)\n",
      "Cut data cells:\n",
      "[[ 9.09913  8.99734  8.62867 ...  8.55276  8.21078  8.22886]\n",
      " [17.18185 17.00076 16.55194 ... 18.05818 17.65871 17.80851]\n",
      " [10.69576 10.49193 10.01953 ...  8.51838  8.12472  8.26212]\n",
      " ...\n",
      " [ 2.1225   1.93251  1.47624 ...  1.58516  1.18929  1.33554]\n",
      " [ 9.2281   9.0396   8.58175 ...  7.71549  7.31146  7.46758]\n",
      " [ 9.01844  8.81586  8.35685 ...  7.58996  7.15511  7.28522]]\n",
      "Filtered data cells:\n",
      "[[ 2.70616862e-15 -2.12979924e-01 -4.68692954e-01 ...  2.96358353e-01\n",
      "   6.78005885e-02  1.06858966e-15]\n",
      " [ 2.42167397e-15 -3.32791796e-01 -6.20281176e-01 ...  2.09838171e-01\n",
      "  -5.38631254e-02  3.60822483e-15]\n",
      " [ 3.93435284e-15 -3.66733481e-01 -6.62942234e-01 ...  2.14771353e-01\n",
      "  -4.28887500e-02  6.03683770e-16]\n",
      " ...\n",
      " [ 5.27355937e-16 -3.47085746e-01 -6.34175555e-01 ...  2.07797848e-01\n",
      "  -5.09210456e-02  2.22044605e-16]\n",
      " [ 2.10942375e-15 -3.41411341e-01 -6.35585419e-01 ...  2.01001598e-01\n",
      "  -5.89745826e-02  1.60982339e-15]\n",
      " [ 1.01307851e-15 -3.58927575e-01 -6.49495024e-01 ...  2.58998529e-01\n",
      "  -2.39895871e-02  1.64451786e-15]]\n"
     ]
    }
   ],
   "source": [
    "print(filtered_data.shape)\n",
    "print(\"Cut data cells:\")\n",
    "print(cut_data)\n",
    "print(\"Filtered data cells:\")\n",
    "print(filtered_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, that size of array remained the same, and data changed, so we assume, that filtering was completed correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Formatting</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In formatting step we should prepare our preprocessed data to further processing. In simple words, we should match constraints of functions we would use later. In our study we work with ICA plotting and vectorizations, so firstly we need to create mne object from our data and info created before:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=8, n_times=50000\n",
      "    Range : 0 ... 49999 =      0.000 ...   199.996 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "mne_data = mne.io.RawArray(filtered_data, info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>After matching data into mne object we need to cut our data into epochs, becasuse it will help us in further processing. Importance of cutting data depends on your goal, but it is commonly used for //TODO uses.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 200 events and 176 original time points ...\n",
      "1 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "def create_epochs(raw_data, duration=1):\n",
    "    \"\"\"\n",
    "    Chops the RawArray onto Epochs given the time duration of every epoch\n",
    "    :param raw_data: mne.io.RawArray instance\n",
    "    :param duration: seconds for copping\n",
    "    :return: mne Epochs class\n",
    "    \"\"\"\n",
    "    events = mne.make_fixed_length_events(raw_data, duration=duration)\n",
    "    epochs = mne.Epochs(raw_data, events, preload=True)\n",
    "    return epochs\n",
    "\n",
    "data_series = create_epochs(mne_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now size of our N-dimensional array changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199, 8, 176)\n"
     ]
    }
   ],
   "source": [
    "print(data_series.get_data().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It became 3D array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Interpretation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//TODO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Visualisation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
